
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>ChatGPT Memory Leak Report</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>
        body { font-family: sans-serif; max-width: 800px; margin: auto; padding: 2em; background: #f9f9f9; color: #222; }
        h1, h2, h3 { color: #b30000; }
        pre { background: #eee; padding: 1em; overflow-x: auto; }
        code { background: #eee; padding: 2px 4px; }
        blockquote { border-left: 4px solid #ccc; margin: 1em 0; padding-left: 1em; color: #555; }
    </style>
</head>
<body>

<h1>ğŸš¨ ChatGPT leaked content from another session â€” memory isolation is broken</h1>

<p>On June 1st, 2025, I caught ChatGPT (GPT-4o, web version) referencing a specific string of text that I <strong>had only typed in another session</strong>.</p>

<blockquote>
<p>The phrase was nonsense in Latin characters â€” something like:<br>
<code>F relf jz cjÃ¼hfzbk rflh</code><br>
...which makes sense <strong>only</strong> if you recognize it as a mistyped Russian sentence using a German QWERTZ keyboard layout.</p>
</blockquote>

<p>I had configured ChatGPT to auto-correct such inputs. But here's the thing:</p>

<h2>This string was <em>never entered</em> in the session where the model reacted to it.</h2>

<ul>
<li>It was never typed or pasted in that session;</li>
<li>It was not stored in memory (I checked my persistent instructions);</li>
<li>It was never mentioned or referred to â€” not even implicitly;</li>
<li>And yet the model interpreted and responded to it directly, as if I had just written it.</li>
</ul>

<h2>ğŸ”¥ This is a memory leak. Plain and simple.</h2>

<p>It means context â€” or some residual token cache â€” <strong>bled from one session into another</strong>. That's a serious breach of OpenAI's claimed session isolation.</p>

<h3>Whatâ€™s worse is:</h3>
<ul>
<li>This happened during active use â€” not during a refresh or restore.</li>
<li>The source session remained inaccessible from the second â€” except for this <em>leaked fragment</em>.</li>
<li>I had no way to control or inspect what crossed the line.</li>
</ul>

<h2>ğŸ§  Why this matters</h2>
<p>OpenAI doesnâ€™t offer local user profiles. You canâ€™t audit what the model sees or retains. All context is server-side and ephemeral â€” except when itâ€™s not.</p>

<h2>ğŸ§¾ What did I do?</h2>
<p>I reported it to OpenAI Security (<code>security@openai.com</code>).</p>
<p>They replied with a boilerplate: <em>â€œPlease submit via Bugcrowd, weâ€™ll follow up if needed.â€</em></p>

<h2>âœ… Can this be verified?</h2>
<p>Yes. I have full logs and screenshots. If anyone seriously wants to validate this, reproduce it, or dig deeper â€” Iâ€™m happy to share details.</p>

<p>This isnâ€™t an edge case. This is a structural failure. And if it happened once â€” it can happen again.</p>

<blockquote><strong>Donâ€™t trust any claims of session isolation until OpenAI proves this cannot happen.</strong><br>
Because right now, I have proof that it can.</blockquote>

</body>
</html>
